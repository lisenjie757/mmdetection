{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export mmdetection model to other format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load mmdetection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/yolov3_mobilenetv1/best_pascal_voc_mAP_epoch_25.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YOLOV3(\n",
       "  (data_preprocessor): DetDataPreprocessor()\n",
       "  (backbone): MobileNetV1(\n",
       "    (layer1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
       "        (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(3, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): YOLOK210Neck(\n",
       "    (convset3): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(320, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (convset2): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (convset1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (downsample1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (downsample2): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bbox_head): YOLOK210Head(\n",
       "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_conf): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_xy): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_wh): MSELoss()\n",
       "    (convs_bridge): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (convs_pred): ModuleList(\n",
       "      (0): Conv2d(96, 125, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmdet.apis import init_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "import torch\n",
    "\n",
    "# 指定模型的配置文件和 checkpoint 文件路径\n",
    "config_file = 'configs/yolo/yolov3_mobilenetv1.py'\n",
    "checkpoint_file = 'work_dirs/yolov3_mobilenetv1/best_pascal_voc_mAP_epoch_25.pth'\n",
    "\n",
    "#Register all modules in mmdet into the registries\n",
    "register_all_modules()\n",
    "# 若检测到有GPU则使用GPU\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 根据配置文件和 checkpoint 文件构建模型\n",
    "model = init_detector(config_file, checkpoint_file, device=device)\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      " \n",
      "Model has been converted to ONNX\n"
     ]
    }
   ],
   "source": [
    "# Let's create a dummy input tensor  \n",
    "dummy_input = torch.randn(1, 3, 224, 224, requires_grad=True, device=device)  \n",
    "\n",
    "# Export the model   \n",
    "torch.onnx.export(model,         # model being run \n",
    "     dummy_input,       # model input (or a tuple for multiple inputs) \n",
    "     \"./outputs/onnx/best_pascal_voc_mAP_epoch_12.onnx\",       # where to save the model  \n",
    "     export_params=True,  # store the trained parameter weights inside the model file \n",
    "     opset_version=11,    # the ONNX version to export the model to \n",
    "     do_constant_folding=True,  # whether to execute constant folding for optimization \n",
    "     input_names = ['modelInput'],   # the model's input names \n",
    "     output_names = ['modelOutput'], # the model's output names \n",
    "     dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes \n",
    "                            'modelOutput' : {0 : 'batch_size'}}) \n",
    "print(\" \") \n",
    "print('Model has been converted to ONNX')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export onnx to kmodel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nncase\n",
    "import onnxsim\n",
    "import onnx\n",
    "import os\n",
    "\n",
    "def parse_model_input_output(model_file):\n",
    "    onnx_model = onnx.load(model_file)\n",
    "    input_all = [node.name for node in onnx_model.graph.input]\n",
    "    input_initializer = [node.name for node in onnx_model.graph.initializer]\n",
    "    input_names = list(set(input_all) - set(input_initializer))\n",
    "    input_tensors = [node for node in onnx_model.graph.input if node.name in input_names]\n",
    "\n",
    "    # input\n",
    "    inputs = []\n",
    "    for _, e in enumerate(input_tensors):\n",
    "        onnx_type = e.type.tensor_type\n",
    "        input_dict = {}\n",
    "        input_dict['name'] = e.name\n",
    "        input_dict['dtype'] = onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[onnx_type.elem_type]\n",
    "        input_dict['shape'] = [(i.dim_value if i.dim_value != 0 else d) for i, d in zip(\n",
    "            onnx_type.shape.dim, [1, 3, 224, 224])]\n",
    "        inputs.append(input_dict)\n",
    "\n",
    "    return onnx_model, inputs\n",
    "\n",
    "def onnx_simplify(model_file):\n",
    "    onnx_model, inputs = parse_model_input_output(model_file)\n",
    "    onnx_model = onnx.shape_inference.infer_shapes(onnx_model)\n",
    "    input_shapes = {}\n",
    "    for input in inputs:\n",
    "        input_shapes[input['name']] = input['shape']\n",
    "\n",
    "    onnx_model, check = onnxsim.simplify(onnx_model, overwrite_input_shapes=input_shapes)\n",
    "    assert check, \"Simplified ONNX model could not be validated\"\n",
    "\n",
    "    model_file = os.path.join(os.path.dirname(model_file), 'best_pascal_voc_mAP_epoch_11_simplified.onnx')\n",
    "    onnx.save_model(onnx_model, model_file)\n",
    "    return model_file\n",
    "\n",
    "def read_model_file(model_file):\n",
    "    with open(model_file, 'rb') as f:\n",
    "        model_content = f.read()\n",
    "    return model_content\n",
    "\n",
    "# onnx simplify\n",
    "model_file = onnx_simplify(\"./outputs/onnx/best_pascal_voc_mAP_epoch_11.onnx\")\n",
    "\n",
    "# compile_options\n",
    "compile_options = nncase.CompileOptions()\n",
    "compile_options.target = 'k210'\n",
    "compile_options.dump_ir = True\n",
    "compile_options.dump_asm = True\n",
    "compile_options.dump_dir = 'tmp'\n",
    "\n",
    "# compiler\n",
    "compiler = nncase.Compiler(compile_options)\n",
    "\n",
    "# import_options\n",
    "import_options = nncase.ImportOptions()\n",
    "\n",
    "# import\n",
    "model_content = read_model_file(model_file)\n",
    "compiler.import_onnx(model_content, import_options)\n",
    "\n",
    "# compile\n",
    "compiler.compile()\n",
    "\n",
    "# kmodel\n",
    "kmodel = compiler.gencode_tobytes()\n",
    "name = os.path.basename(model_file).split(\".\")[0]\n",
    "with open(f'{name}.kmodel', 'wb') as f:\n",
    "    f.write(kmodel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (tinynn.converter.base) Generated model saved to ./outputs/tflite/k210_tflite_v2.tflite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tinynn.converter import TFLiteConverter\n",
    "\n",
    "dummy_input = torch.rand((1, 3, 224, 224))\n",
    "\n",
    "output_path = os.path.join('./outputs/tflite/k210_yolo_v2.tflite')\n",
    "\n",
    "# When converting quantized models, please ensure the quantization backend is set.\n",
    "#torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "# The code section below is used to convert the model to the TFLite format\n",
    "# If you want perform dynamic quantization on the float models,\n",
    "# you may refer to `dynamic.py`, which is in the same folder.\n",
    "# As for static quantization (e.g. quantization-aware training and post-training quantization),\n",
    "# please refer to the code examples in the `examples/quantization` folder.\n",
    "converter = TFLiteConverter(model, dummy_input, output_path)\n",
    "converter.convert()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export onnx to tflite (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf\n",
    "\n",
    "TF_PATH = \"./outputs/pb/best_pascal_voc_mAP_epoch_135.pb\" # where the representation of tensorflow model will be stored\n",
    "ONNX_PATH = \"./outputs/onnx/best_pascal_voc_mAP_epoch_135_simplified.onnx\" # path to my existing ONNX model\n",
    "onnx_model = onnx.load(ONNX_PATH)  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # creating TensorflowRep object\n",
    "tf_rep.export_graph(TF_PATH)\n",
    "\n",
    "TFLITE_PATH = \"./outputs/pb/best_pascal_voc_mAP_epoch_135.tflite\"\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(TF_PATH)\n",
    "## 启用量化配置\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tf_lite_model = converter.convert()\n",
    "with open(TFLITE_PATH, 'wb') as f:\n",
    "    f.write(tf_lite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
