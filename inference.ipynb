{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference mmdetection model from other format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inference mmdetection pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/yolov3_mobilenetv2_pretrained/best_pascal_voc_mAP_epoch_27.pth\n",
      "[[  1   2 348 496  14   1]\n",
      " [ 64 245 171 365  11   1]]\n",
      "<DetDataSample(\n",
      "\n",
      "    META INFORMATION\n",
      "    scale_factor: (0.4475920679886686, 0.448)\n",
      "    batch_input_shape: (224, 160)\n",
      "    ori_shape: (500, 353)\n",
      "    img_id: 0\n",
      "    pad_shape: (224, 160)\n",
      "    img_shape: (224, 158)\n",
      "    img_path: None\n",
      "\n",
      "    DATA FIELDS\n",
      "    gt_instances: <InstanceData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            bboxes: tensor([], size=(0, 4))\n",
      "            labels: tensor([], dtype=torch.int64)\n",
      "        ) at 0x7f06cadc86a0>\n",
      "    ignored_instances: <InstanceData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            bboxes: tensor([], size=(0, 4))\n",
      "            labels: tensor([], dtype=torch.int64)\n",
      "        ) at 0x7f06cadca8f0>\n",
      "    pred_instances: <InstanceData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            bboxes: tensor([[  1.4124,   2.3510, 347.7869, 496.0396],\n",
      "                        [ 63.7587, 245.1837, 171.3031, 365.1945],\n",
      "                        [ 63.7587, 245.1837, 171.3031, 365.1945]])\n",
      "            labels: tensor([14, 11,  7])\n",
      "            scores: tensor([0.9992, 0.6674, 0.3348])\n",
      "        ) at 0x7f06cadca350>\n",
      ") at 0x7f06cadca200>\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, async_inference_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "# 指定模型的配置文件和 checkpoint 文件路径\n",
    "config_file = 'configs/yolo/yolov3_mobilenetv2_8xb24-ms-416-300e_coco.py'\n",
    "checkpoint_file = 'work_dirs/yolov3_mobilenetv2_pretrained/best_pascal_voc_mAP_epoch_27.pth'\n",
    "\n",
    "#Register all modules in mmdet into the registries\n",
    "register_all_modules()\n",
    "# 若检测到有GPU则使用GPU\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 根据配置文件和 checkpoint 文件构建模型\n",
    "model = init_detector(config_file, checkpoint_file, device=device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 定义预处理方法\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载图像并进行预处理\n",
    "image = Image.open('../data/VOCdevkit/VOC2007/test_img/000001.jpg')\n",
    "image_tensor = preprocess(image)\n",
    "# 添加一个维度以匹配模型的输入\n",
    "image_tensor = image_tensor.unsqueeze(0)\n",
    "output = model(image_tensor)\n",
    "\n",
    "\n",
    "img = mmcv.imread( '../data/VOCdevkit/VOC2007/test_img/000001.jpg', channel_order='rgb')\n",
    "output2 = inference_detector(model, img)\n",
    "\n",
    "output3 = torch.cat((output2.pred_instances['bboxes'], output2.pred_instances['labels'].unsqueeze(1), \n",
    "                     output2.pred_instances['scores'].unsqueeze(1)), dim=1).numpy()\n",
    "output3 = np.rint(output3[:-1]).astype(np.int32)\n",
    "print(output3)\n",
    "print(output2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
