{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.fileio import list_from_file\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import xmltodict\n",
    "import mmcv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class_dict = {\n",
    "    'aeroplane': 0,\n",
    "    'bicycle': 1,\n",
    "    'bird': 2,\n",
    "    'boat': 3,\n",
    "    'bottle': 4,\n",
    "    'bus': 5,\n",
    "    'car': 6,\n",
    "    'cat': 7,\n",
    "    'chair': 8,\n",
    "    'cow': 9,\n",
    "    'diningtable': 10,\n",
    "    'dog': 11,\n",
    "    'horse': 12,\n",
    "    'motorbike': 13,\n",
    "    'person': 14,\n",
    "    'pottedplant': 15,\n",
    "    'sheep': 16,\n",
    "    'sofa': 17,\n",
    "    'train': 18,\n",
    "    'tvmonitor': 19\n",
    "}\n",
    "\n",
    "# 指定要遍历的文件夹路径\n",
    "img_ids = list_from_file(\"../data/VOCdevkit/VOC2007/ImageSets/Main/test.txt\")\n",
    "\n",
    "annotations, det_results  = [], []\n",
    "for j in range(len(img_ids)):\n",
    "\n",
    "    # 解析XML文件\n",
    "    ann_path = os.path.join('../data/VOCdevkit/VOC2007/Annotations/', img_ids[j] + '.xml')\n",
    "    with open(ann_path) as f:\n",
    "        xml_data = xmltodict.parse(f.read())\n",
    "    bboxes, labels = [], []\n",
    "    bboxes_ignore, labels_ignore = [], []\n",
    "    obj = xml_data['annotation']['object']\n",
    "    if type(obj) == list:\n",
    "        for i in range(len(obj)):\n",
    "            if obj[i]['difficult'] == '0':\n",
    "                bboxes.append([int(obj[i]['bndbox']['xmin'])-1, int(obj[i]['bndbox']['ymin'])-1, \n",
    "                            int(obj[i]['bndbox']['xmax'])-1, int(obj[i]['bndbox']['ymax'])-1])\n",
    "                labels.append(class_dict[obj[i]['name']])\n",
    "            else:\n",
    "                bboxes_ignore.append([int(obj[i]['bndbox']['xmin'])-1, int(obj[i]['bndbox']['ymin'])-1, \n",
    "                            int(obj[i]['bndbox']['xmax'])-1, int(obj[i]['bndbox']['ymax'])-1])\n",
    "                labels_ignore.append(class_dict[obj[i]['name']])\n",
    "    else:\n",
    "        if obj['difficult'] == '0':\n",
    "            bboxes.append([int(obj['bndbox']['xmin'])-1, int(obj['bndbox']['ymin'])-1, \n",
    "                        int(obj['bndbox']['xmax'])-1, int(obj['bndbox']['ymax'])-1])\n",
    "            labels.append(class_dict[obj['name']])\n",
    "        else:\n",
    "            bboxes_ignore.append([int(obj['bndbox']['xmin'])-1, int(obj['bndbox']['ymin'])-1, \n",
    "                        int(obj['bndbox']['xmax'])-1, int(obj['bndbox']['ymax'])-1])\n",
    "            labels_ignore.append(class_dict[obj['name']])\n",
    "\n",
    "    bboxes = torch.tensor(bboxes).cpu().numpy().astype(np.float32)\n",
    "    labels = torch.tensor(labels).cpu().numpy()\n",
    "    bboxes_ignore = torch.tensor(bboxes_ignore).cpu().numpy().astype(np.float32)\n",
    "    labels_ignore = torch.tensor(labels_ignore).cpu().numpy()\n",
    "\n",
    "    ann = {'bboxes': bboxes,\n",
    "           'labels': labels,\n",
    "           'bboxes_ignore': torch.empty(size=(0,4)).cpu().numpy() if len(bboxes_ignore) == 0 else bboxes_ignore,\n",
    "           'labels_ignore': torch.empty(dtype=torch.int64, size=(0,)).cpu().numpy() if len(labels_ignore) == 0 else labels_ignore}\n",
    "    annotations.append(ann)\n",
    "\n",
    "    \n",
    "    # 加载图像并进行预处理\n",
    "    preds_path = os.path.join('../data/VOCdevkit/VOC2007/test_img_preds/', img_ids[j] + '.txt')\n",
    "    with open(preds_path, 'r') as f:\n",
    "        preds = f.read()\n",
    "    preds = eval(preds)\n",
    "    \n",
    "    scale_factor = (320.0/int(xml_data['annotation']['size']['width']),\n",
    "                    240.0/int(xml_data['annotation']['size']['height']))\n",
    "    \n",
    "    pred_bboxes = np.empty(shape=(0,4))\n",
    "    pred_scores = np.empty(shape=(0))\n",
    "    pred_labels = np.empty(shape=(0))\n",
    "    if preds is not None:\n",
    "        for pred in preds:\n",
    "            pred_bboxes = np.append(pred_bboxes, [[pred['x'], pred['y'], pred['x']+pred['w'], pred['y']+pred['h']]], axis=0)\n",
    "            pred_scores = np.append(pred_scores, pred['value'])\n",
    "            pred_labels = np.append(pred_labels, pred['classid'])\n",
    "\n",
    "    pred_bboxes[:,[0,2]] /= scale_factor[0]\n",
    "    pred_bboxes[:,[1,3]] /= scale_factor[1]    \n",
    "\n",
    "    dets = []\n",
    "    for label in range(len(class_dict)):\n",
    "        index = np.where(pred_labels == label)[0]\n",
    "        pred_bbox_scores = np.hstack(\n",
    "            [pred_bboxes[index], pred_scores[index].reshape((-1, 1))])\n",
    "        dets.append(pred_bbox_scores)\n",
    "    \n",
    "    det_results.append(dets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------+------+-------+--------+-------+\n",
      "| class | gts  | dets  | recall | ap    |\n",
      "+-------+------+-------+--------+-------+\n",
      "| 0     | 285  | 3330  | 0.246  | 0.139 |\n",
      "| 1     | 337  | 3867  | 0.415  | 0.227 |\n",
      "| 2     | 459  | 6100  | 0.264  | 0.111 |\n",
      "| 3     | 263  | 4873  | 0.270  | 0.125 |\n",
      "| 4     | 469  | 13181 | 0.166  | 0.096 |\n",
      "| 5     | 213  | 3155  | 0.371  | 0.157 |\n",
      "| 6     | 1201 | 14468 | 0.280  | 0.093 |\n",
      "| 7     | 358  | 3144  | 0.425  | 0.222 |\n",
      "| 8     | 756  | 18377 | 0.340  | 0.130 |\n",
      "| 9     | 244  | 2962  | 0.332  | 0.145 |\n",
      "| 10    | 206  | 4502  | 0.330  | 0.157 |\n",
      "| 11    | 489  | 5380  | 0.405  | 0.184 |\n",
      "| 12    | 348  | 2501  | 0.434  | 0.188 |\n",
      "| 13    | 325  | 3064  | 0.363  | 0.141 |\n",
      "| 14    | 4528 | 37066 | 0.422  | 0.259 |\n",
      "| 15    | 480  | 11084 | 0.227  | 0.111 |\n",
      "| 16    | 242  | 3632  | 0.314  | 0.150 |\n",
      "| 17    | 239  | 4488  | 0.347  | 0.132 |\n",
      "| 18    | 282  | 3330  | 0.340  | 0.108 |\n",
      "| 19    | 308  | 6063  | 0.403  | 0.238 |\n",
      "+-------+------+-------+--------+-------+\n",
      "| mAP   |      |       |        | 0.156 |\n",
      "+-------+------+-------+--------+-------+\n"
     ]
    }
   ],
   "source": [
    "from mmdet.evaluation.functional.mean_ap import eval_map\n",
    "\n",
    "mean_ap, eval_results = eval_map(det_results, annotations, eval_mode='11points', use_legacy_coordinate=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
